# 从0到1学会Apache Flink读书笔记
## 第一章 Runtime核心机制剖析
- Flink Runtime：Flink提供的统一的分布式作业执行引擎，这之上提供了Data Stream和DataSet两套API，分别用于编写流作业与批作业，以及一组更高级的API来简化特定作业的编写
- Runtime采用Master-Slave结构
- Master包含三个组件（AM进程中）：
    - Dispatcher：负责接收用户提供的作业，为其拉起一个新的JobManager组件
    - ResourceManager：负责资源的管理，整个Flink集群只有一个RM
    - JobManager：负责管理作业的执行，每个作业都有自己的JM
- 基于上述结构的作业提交过程：
    - 提交脚本启动一个Client进程负责作业的编译与提交
    - Client将用户代码编译为一个JobGraph，过程中会检查与优化
    - Client将JobGraph提交到集群中执行
    - 若AM已启动（Session模式），Client直接与Dispatcher建立连接提交作业
    - 若AM未启动（Per-Job模式），Client先向资源管理系统（Yarn、K8S）申请资源启动AM，再向其中Dispatcher提交作业
    - Dispatcher收到作业后，会启动一个JobManager组件
    - JobManager向ResourceManager申请资源启动任务
    - 若RM已有记录TaskExecutor注册的资源（Session模式），可以直接选取空闲资源进行分配。若无（Per-Job），RM也需要首先向外部资源管理系统申请资源来启动TaskExecutor，然后等待TaskExecutor注册相应资源后再继续选择空闲资源进程分配（TaskExecutor的资源通过Slot描述）
    - RM选择到空闲的Slot后会通知相应的TM将该Slot分配给哪个JM
    - TaskExecutor进行相应记录后，向JM注册
    - JM收到TaskExecutor注册的Slot后，进行实际的Task提交
    - TaskExecutor收到JM提交的Task后，会启动一个线程用于执行Task
- Per-Job模式下AM和TaskExecutor按需申请，适合长时作业，对稳定性要求高，且对资源申请时间不敏感
- Session模式适合规模小、执行时间短的作业
- 资源管理
    - ResourceManager中有个子组件SlotManager，维护当前集群中所有TaskExecutor上的Slot信息与状态（位于哪个TaskExecutor中、是否空闲等）
    - TaskExecutor启动后，会通过服务发现找到当前活跃的RM并进行注册，注册信息包含所有Slot的信息
    - RM收到注册后会让SlotManager记录Slot信息，以便日后JM来申请资源时可以从中选取Slot进行分配（按一定规则）
    - 分配完成后，RM向TM发送RPC请求要求其将指定Slot分给指定JM
    - TM如果没执行过该JM的任务，则需要先向该JM建立连接，然后发送提供slot的RPC请求
    - JM中，所有Task的请求会缓存到SlotPool中，当有Slot被提供时，从缓存池里取出相应的请求并结束其请求过程
    - Task结束后会通知JM结束状态（是否有异常），然后TM将slot标记为已占用但未执行任务。JM也会把Slot放进SlotPool里，但不会立即释放，以免需要重启任务时要重新申请Slot
    - SlotPool里缓存的Slot在超过指定时间后JM才会申请释放，与申请Slot一样，先通知TM来释放slot，然后TaskExecutor通知RM该slot已释放
    - TM与RM，TM与JM之间会心跳保活
    - Share Slot机制可以允许每个Slot中部署来自不同JobVertex的Task，以提高资源利用率，并做一点简单的负载均衡
    - JM会对JobGraph按并发展开得到ExecutionGraph，其会对每个任务的中间结果等均创建对应的对象，从而可以维护这些实体的信息与状态
- 作业调度
    - Eager：作业启动时申请资源将所有Task调度起来，一般用于没有终止的流作业
    - Lazy From Source：从Source开始按拓扑顺序按需调度，前面任务结果产出后再起下游任务（中间结果需要内存缓存或落磁盘）
- 错误恢复
    - Task执行错误
        - Restart-all：直接重启所有Task，可以通过Checkpoint从最近一次检查点继续执行，适合于流作业
        - Restart-individual：当Task间没有数据传输的时候可以直接重启出错的任务
    - 对于批作业而言，可以使用Regional重启的策略。一条Pipeline作业处理线就是一个Region（两端以批作业分隔），因为region之间数据会缓存，因此regin可以单独重启。此时ExecutionGraph可以划分为多个子图（有点像MapReduce里不同的Stage）
    - 在Region策略中，如果上游输出结果时出现问题（如TaskExecutor异常退出等），则还需要重启上游Region来重新产生相应数据。若上游输出数据的分发方式不确定（KeyBy、Broadcast属于确定，Rebalance、Random属于不确定），则为了保证结果正确性，还需要把上游region对应的所有下游region也一块重启
    - Flink集群支持多个Master备份，如果Master挂了，可以通过Zookeeper重新选主并接管工作，但为了准确维护作业状态，需要重启整个作业（有改进空间）
