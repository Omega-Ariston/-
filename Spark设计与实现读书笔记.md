# 第一部分 大数据处理框架的基础知识
## 第1章 大数据处理框架概览
### 1.4 大数据处理框架的四层结构
- 一个大数据应用可以表示为<输入数据，用户代码，配置参数>。应用的输入数据一般以分块（如128MB）的形式预先存储在分布式文件系统（如HDFS）上。用户在向大数据处理框架提交应用之前，需要指定数据存储位置，撰写数据处理代码，并设定配置参数。之后用户将应用提交给大数据处理框架运行。
- 大数据处理框架大体可以分为四层结构：用户层、分布式数据并行处理层、资源管理与任务调度层、物理执行层。
- 以Spark为例，在用户层中，用户需要准备数据、开发用户代码、配置参数。之后，分布式数据并行处理层根据用户代码和配置参数，将用户代码转化成逻辑处理流程（数据单元及数据依赖关系），然后将逻辑处理流程转化为物理执行计划（执行阶段及执行任务）。资源管理与任务调度层根据用户提供的资源需求来分配资源容器，并将任务（taks）调度到合适的资源容器上运行。物理执行层实际运行具体的数据处理任务。
#### 1.4.1 用户层
- 如前所述，将一个大数据应用表示为<输入数据，用户代码，配置参数>
1. 输入数据
    - 对于批式大数据处理框架，如Hadoop、Spark，一般以分块的形式预先存储，可以存在分布式文件系统如HDFS或分布式KV数据库如HBase上，也可以存放到关系数据库中。输入数据在应用提交后会由框架进行自动分块，每个分块一般对应一个具体执行任务（task）。
    - 对于流式大数据处理框架，如Spark Streaming和Flink，输入数据可以来自网络流（socket）、消息队列（kafka）等。数据以微批（多条数据形成一个微批，称为mini-batch）或者连续（一条接一条，称为continuous）的形式进入流式大数据处理框架。
    - 对于大数据应用，数据的高效读取常常成为影响系统整体性能的重要因素。最直观的优化方式就是降低磁盘I/O。如PACMan根据一定策略提前将task所需部分数据缓存到内存中，以提高task的执行性能。Tachyon（Alluxio）构造了一个基于内存的分布式数据存储系统，用户可以将不同应用产生的中间数据缓存到Alluxio中，而不是直接缓存到框架中，可以加速中间数据的写入和读取，以及框架的内存消耗，以实现加速不同的大数据应用（如Hadoop、Spark等）之间的数据传递和共享
2. 用户代码
    - 可以是用户写手的MR代码，或基于其他大数据处理框架的具体应用处理流程的代码。
    - MR提供的map和reduce函数的处理逻辑比较固定单一，难以支持复杂数据操作，比如常见的排序操作sort和数据库表的关联操作join等。因此Dryad和Spark提供了更加通用的数据操作符，如flatMap等。
    - 在实际系统中，用户撰写用户代码后，大数据处理框架会生成一个Driver程序，将用户代码提交给集群运行。例如在Hadoop MapReduce中，Driver程序负责设定输入、输出数据类型，并向MR框架提交作业；在Spark中，Driver程序不仅可以产生数据、广播数据给各个task，还可以收集task的运行结果，最后在Driver程序的内存中计算出最终结果。
    - 除了手写底层操作代码，用户还可以利用高层语言或高层库来间接产生用户代码，通过这种方式生成的代码是二进制的，map和reduce等函数代码不可见。
    - 一些高层库还提供了更简单的方式生成用户代码，如使用Spark的机器学习库MLlib时，用户只需要选择算法和设置算法参数，MLlib即可自动生成可执行的Spark作业了。
3. 配置参数
    - 一个大数据应用可以有很多配置参数，如Hadoop支持200多个配置参数。这些配置参数可以分为两大类：
    1. 与资源相关的配置：例如buffer size定义框架缓冲区的大小，影响map/reduce任务的内存用量。在Hadoop中，map/reduce任务实际启动一个JVM来运行，因此用户还要设置JVM的大小，也就是heap size。在Spark中，map/reduce任务在资源容器（Executor JVM）中以线程的方式执行，用户需要估算应用的资源需求量，并设置应用需要的资源容器个数、CPU个数和内存大小。
    2. 与数据流相关的配置：例如，Hadoop和Spark中者可以设置partition函数、partition个数和数据分块大小。partition函数定义如何划分map的输出数据。partition个数定义产生多少个数据块，也就是有多少个reduce任务会被运行。数据分块大小定义map任务的输入数据大小。
    - Hadoop/Spark框架本身没有提供自动优化配置参数的功能，因此工业界和学术界研究了如何通过寻找最优配置参数来对应用进行性能调优。几个例子：
    1. StarFish的Just-In-Time优化器，可以对Hadoop应用的历史运行信息进行分析，并根据分析结果来预测应用在不同配置参数下的执行时间，以选择最优参数。
    2. Verma等讨论了在给定应用完成时限的情况下，如何为Hadoop应用分配最佳的资源（map/reduce slot）来保证应用能够在给定时限内完成。
    3. DynMR通过调整任务启动时间、启动顺序、任务个数来减少任务等待时间和由于过早启动而引起的任务之间资源竞争。
    4. MROnline根据任务执行状态，使用爬山法寻找最优的缓冲区大小和任务内存大小，以减少应用执行时间。
    5. Xu等研究了如何离线估计MapReduce应用内存用量，即先用小样本数据运行应用，然后根据应用运行信息来估算应用在大数据上的实际内存消耗。
    6. SkewTune可以根据用户自定义的代码函数来优化数据划分算法，在保持数据输入顺序的同时，减少数据倾斜的问题。
#### 1.4.2 分布式数据并行处理层
- 分布式数据并行处理层首先将用户提交的应用转化为较小的应用任务，然后通过调用底层的资源管理与任务调度层实现并行执行。
- 在Hadoop MapReduce中，这个转化过程是直接的，因为MR具有固定的执行流程：map-shuffle-reduce。map和reduce阶段各自包含多个可以并行执行的任务。map负责将输入的分块数据进行map处理，并将其输出结果写入缓冲区，然后对缓冲区中的数据进行分区、排序、聚合等操作，最后溢写到磁盘上的不同分区中。reduce则首先将map任务输出的对应分区数据通过网络传输拷贝到本地内存中，内存空间不够时，会将内存数据排序后写入磁盘，然后经过归并、排序等阶段产生reduce的输入数据。reduce处理完输入数据后，将输出数据写入分布式文件系统中。
- 在Spark中应用的转化过程包含两层：逻辑处理流程、执行阶段与执行任务划分。
- Spark首先根据用户代码中的数据操作语义和操作顺序，将代码转化为逻辑处理流程。逻辑处理流程包含多个数据单元和数据依赖，每个数据单元包含多个数据分块。然后，框架对逻辑处理流程进行划分，生成物理执行计划。该计划包含多个执行阶段（stage），每个执行阶段包含若干执行任务（task）。
- 为了将用户代码转化为逻辑处理流程，Spark对输入/输出、中间数据进行了更具体的抽象处理，将这些数据用一个统一的数据结构表示，即RDD（Resilient Distributed Datasets，弹性分布式数据集）。
- 在RDD上可以执行多种数据操作，如简单的map以及复杂的cogroup、join等。
- 一个RDD可以包含多个数据分区（partition），parentRDD和childRDD之间通过数据依赖关系关联，支持一对一和多对一等数据依赖关系。数据依赖关系的类型由数据操作的类型决定。
- 为了将逻辑处理流程转化为物理执行阶段，Spark首先根据RDD之间的数据依赖关系，将整个流程划分为多个小的执行阶段（stage）。之后，在每个执行阶段形成计算任务（task），计算任务的个数一般与RDD中分区的个数一致。
- 与MR不同的是，一个Spark job可以包含很多个执行阶段，而且每个执行阶段可以包含多种计算任务，因此并不能严格地区分每个执行阶段中的任务是map任务还是reduce任务。
- 在Spark中，用户可以通过调用cache接口使框架缓存可被重用的中间数据。例如，当前job的输出可能会被下一个job用到，那么用户可以使用cache()来对这些数据进行缓存。
#### 1.4.3 资源管理与任务调度层
- 从系统架构上讲，大数据处理框架一般是主-从结构（Master-Worker）。主节点负责接收用户提交的应用，处理请求，管理应用运行的整个生命周期。从节点负责执行具体的数据处理任务，并在运行过程中向主节点汇报任务的执行状态。比如在Hadoop MapReduce中，在主节点运行的JobTracker进程首先接收用户提交的job，然后根据job的输入数据和配置等信息将job分解为具体的数据处理任务，然后将task交给任务调度器调度运行。任务调度器根据各个从节点的资源总量与资源使用情况将map/reduce task分发到合适的从节点的TaskTracker中。TaskTracker进程会为每个task启动一个进程执行task的处理步骤。每个从节点可以同时运行的task数目由该节点的CPU个数等资源状况决定。
- 大数据处理服务器集群一般由多个用户共享，当集群资源充足的情况下，集群会同时运行多个job，每个job包含多个map/reduce task。同一个节点上运行的task可以属于不同的job。
- Spark运行不同的部署模式，如Standalone、YARN和Mesos模式。其中Standalone模式与MR部署模式基本类似，唯一区别是MR部署模式为每个task启动一个JVM进程运行，而且是在task将要运行时启动JVM，而Spark是预先启动资源容器（Executor JVM），然后当需要执行task时，再在容器里启动task线程运行。
- 在运行大数据应用前，框架还需要对应用job及其任务task进行调度，主要目的是通过设置不同的策略来决定应用或任务获得资源的先后顺序。典型的调度方式有FIFO和Fair等。
- 调度器有两种类型：应用调度器（决定多个应用app执行的先后顺序）和任务调度器（决定多个任务task的执行先后顺序）。
#### 1.4.4 物理执行层
- 物理执行层负责启动task，执行每个task的数据处理步骤。
- 不像MR的map、shuffle、reduce，Spark中一个应用可以有更多的执行阶段stage，如迭代型应用可能有几十个执行阶段，每个执行阶段也包含多个task。这些执行阶段可以形成复杂的DAG图结构，在物理执行时首先执行上游stage中的task，完成后执行下游stage中的task。
- MR中每个task对应一个进程，以JVM的方式来运行，因此task的内存用量就是JVM的堆内存用量。
- Spark中每个task对应JVM中的一个线程，一个JVM可能同时运行了多个task。在应用未运行前，难以预知task的内存消耗和执行时间，以JVM的堆内存用量。
- 从应用特点分析，可以将task执行过程中主要消耗内存的数据分为以下3类：
    1. 框架执行时的中间数据：例如map输出到缓冲区的数据和reduce在shuffle阶段暂存到内存中的数据。
    2. 框架缓存数据：例如在Spark中，用户调用cache接口缓存到内存中的数据。
    3. 用户代码产生的中间计算结果：例如用户代码调用map、reduce、combine，在处理输入数据时会在内存中产生中间计算结果。
- Spark框架是基于内存计算的，它将大量输入数据和中间数据缓存到了内存中，有效提高交互型job和迭代型job的执行效率。
- 由于大数据应用的内存消耗量很大，当前许多研究关注如何改进大数据处理框架的内存管理机制，以减少应用内存消耗。

## 第2章 Spark系统部署与应用运行的基本流程
### 2.2 Spark系统架构
- Spark application：即Spark应用，指的是1个可运行的Spark程序，该程序包含main函数，其数据处理流程一般先从数据源读取数据，再处理数据，最后输出结果。同时，应用程序也包含了一些配置参数，如需要占用的CPU个数，Executor内存大小等。用户可以使用Spark本身提供的数据操作来实现程序，也可以通过其它框架（如Spark SQL）来实现应用，Spark SQL可以将SQL语句转化成Spark程序执行。
- Spark Driver：即Spark驱动程序，指实际在运行Spark应用中main函数的进程。Driver一般位于Master节点上，但独立于Master进程。如果是YARN集群，Driver也可能被调度到Worker节点上运行。也可以在自己的PC上运行Driver，通过网络与远程的Master进程连接，但一般不推荐这么做，因为不但需要本地安装一个与集群一样的Spark版本，而且自己的PC一般和集群不在一个网段，Driver和Worker节点之间的通信会很慢。
- Executor：即Spark执行器，是Spark计算资源的一个单位。Spark先以Executor为单位占用集群资源，然后可以将具体的计算任务分配给Executor执行。由于Spark是由Scala编写的，Executor在物理上是一个JVM进程，可以运行多个线程（任务）。
- task：即Spark应用的计算任务。Driver在运行Spark应用的main函数时，会将应用拆分成多个计算任务，然后分配给多个Executor执行。task是Spark中最小的计算单位，不能再拆分。task以线程方式运行在Executor进程中，执行具体的计算任务，如map算子、reduce算子等。由于Executor可以配置多个CPU，而1个task一般使用1个CPU，因此当Executor具有多个CPU时，可以运行多个task。Executor的总内存大小由用户配置，其由多个task共享。
- Hadoop MR中的每个task以一个JVM进程的方式运行，好处是可以让task之间相互独立，每个task独享进程资源，不会相互干扰，而且监控管理比较方便，但坏处是task之间不方便共享数据（需要将共享数据加载到每个task进程中，造成重复加载和内存资源浪费），并且在应用执行过程中需要不断启停新旧task，进程的启动和停止需要做很多初始化工作，会降低执行效率。
- Spark中的每个task以JVM中的一个线程的方式运行，好处是数据共享和执行效率得到提高，坏处是线程间会有资源竞争，而且Executor JVM的日志会包含多个并行task的日志，较为混乱。
- 每个Worker进程中存在一个或者多个ExecutorRunner对象，每个对象管理一个Executor。Executor持有一个线程池，每个线程执行一个task。
- Worker进程通过持有一个或多个ExecutorRunner对象来控制各自对应的CoarseGrainedExecutorBackend进程的启停（Executor位于其中）
- 每个Spark应用启动一个Driver和多个Executor，每个Executor里面运行的task都属于同一个Spark应用。
### 2.3 Spark应用例子
### 2.3.1 用户代码基本逻辑
- 一般不需要在编写应用时指定map task的个数，因为其可以通过“输入数据的大小/每个分片大小”来决定，而reduce task的个数一般在使用算子时通过设置partition number来间接设置。
- Spark编程与使用普通语言编写数据处理程序的不同：
    - 使用普通语言编程：处理的数据在本地，程序也在本地进程中运行，可以随意定义变量、函数、控制流（分支、循环）等，编程灵活、受限较少，且程序按照既定顺序执行、输出结果。
    - 使用Spark编程：首先要声明SparkSession的环境变量才能够使用Spark提供的数据操作，然后使用Spark操作来定义数据处理流程。此时只是定义了数据处理流程，而并没有让Spark真正开始计算，就像在一个画布上画出了数据处理流程，包括哪些数据处理步骤以及这些步骤如何连接，每步的输入和输出是什么。至于这些步骤和操作如何在系统中并行执行，用户并不需要关心。有点像SQL的执行。
- 在Spark中，唯一需要注意声明的数据处理流程在使用action()操作时，Spark才真正执行处理流程，如果整个程序中没有action操作，就不会执行数据处理流程。而在普通程序中程序一步步按照顺序执行，无此限制。
### 2.3.2 逻辑处理流程
- 先建立DAG型的逻辑处理流程(Logical plan)，然后根据逻辑处理流程生成物理执行计划(Physical plan)，后者包含具体的计算任务task，最后Spark将task分配到多台机器上执行。
### 2.3.3 物理执行计划
- Spark根据数据依赖关系，将逻辑处理流程转化为物理执行计划，包括执行阶段stage和执行任务task。具体包括下面三个步骤：
    1. 确定应用会产生哪些作业（job），一般情况下对应action操作的个数。（有时一个action可以被优化为多个作业，如某些情况下的saveAsTextFile，或有时没有明显action也会启动作业，如foreach等操作）
    2. 根据逻辑处理流程中的数据依赖关系，将每个job的处理流程拆分为执行阶段stage。如果两个RDD是一对一的关系则可以放在一起处理形成一个stage。多对多的RDD则会被分别处理形成两个stage。
    3. 对于每一个stage，根据RDD的分区个数确定执行的task个数和种类。
- 生成task后，task可以被调度到Executor上执行，在同一个stage中的task可以并行执行。
- 拆分stage的好处：
    1. stage中生成的task不会太大，也不会太小，而且是同构的，便于并行执行。
    2. 可以将多个操作放在一个task里处理，使得操作可以进行串行、流水线式的处理，提高数据处理效率。
    3. stage可以方便错误容忍，比如一个stage失效时可以重新运行这个stage，而不是整个job。
### 2.3.4 可视化执行过程
- 可以根据Spark提供的执行界面，即Job UI来分析一个Spark应用的逻辑处理流程和物理执行计划。
- 可以根据stage的task个数来判断RDD的分区个数。