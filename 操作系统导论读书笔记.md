# 操作系统导论读书笔记
## 第一部分 虚拟化
### 第二章 操作系统介绍
- 冯·诺依曼计算模型基本概念：处理器从内存中获取一条指令，对其进行解码，然后执行它，完成这条指令后处理器继续执行下一条指令，直到程序最终完成
- 虚拟化：操作系统将物理资源（如处理器、内存或磁盘）转换为更通用、更强大且更易于使用的虚拟形式。因此操作系统亦被称作虚拟机
- 操作系统会提供系统调用（几百个）让应用程序使用，它们可被用于运行程序、访问内存和设备，并进行其它操作。这些系统调用的集合亦被称作标准库

### 第四章 抽象：进程
- 进程API：创建、销毁、等待、其它控制（如暂停、继续）、状态
- 进程创建：
    1. 从磁盘中将代码和静态数据加载到内存中
    2. 为程序的运行时栈分配内存（如局部变量、函数参数、返回地址），并用参数初始化栈（将argc、argv数组参数填入main函数）
    3. 为程序的堆分配内存（通过调用malloc函数进行分配以及调用free函数进行释放）
    4. 执行其它初始化任务，特别是I/O相关任务，例如UNIX系统中每个进程的3个打开文件描述符：标准输入、标准输出、错误
    5. 启动程序，在入口处运行（main方法）

### 第五章 插叙：进程API
- fork：子进程与父进程几乎完全一样（子进程不会从main方法开始执行，而是从fork方法返回处开始执行，就像是它自己调用了fork一样。子进程与父进程有不同的返回值，子进程返回0，父进程返回子进程pid）
- wait：调用wait方法后父进程会等待所有子进程执行完毕后再返回
- exec：与fork不同的地方在于fork创建的是父子一样的进程，而exec可以为子进程指定新的程序内容，包括加载新的代码和静态数据（在原始子进程上直接替换）。对exec的成功调用永远不会返回，仿佛子进程在运行exec之前的事情从未发生过一般

### 第六章 机制：受限直接执行
- 构建CPU虚拟化机制的挑战：
    1. 尽可能少地增加系统开销
    2. 有效地运行进程同时要保留对CPU的控制权
- 内核通过在启动时设置陷阱表来约束系统调用。当机器启动时，它在内核模式下执行，因此可以根据需要自由配置机器硬件
- 操作系统做的第一件事就是告诉硬件在发生某些异常事件时要运行哪些代码，如硬盘中断、键盘中断、或程序进行系统调用时应该执行的代码。当硬件被通知到这些代码位置后，会记录下来直至下一次重新启动机器
- main函数结束后会返回到内核模式下的一些存根代码，用于正确地退出程序（如通过exit系统调用）
- 当进程发生切换时，OS会将A进程的内核寄存器保存在特定数据结构中，并将B进程的内核寄存器从特定的数据结构中恢复。如此一来，A进程刚刚陷入内核状态就变得像是B进程刚刚陷入了内核状态

### 第七章 进程调度：介绍
- 进程调度需要考虑的指标：周转时间（最短完成任务优先）、响应时间（时间片轮转）。这两个指标通常无法同时满足，需要权衡
- 上下文切换的成本不仅仅来自保存和恢复少量寄存器的操作系统操作，还有CPU高速缓存、TLB、分支预测器和其它片上硬件中建立的大量状态也会被刷新，可能导致显著的性能成本
- 处理带有I/O操作的任务时，可以将每次CPU请求作为一个单独的任务看待（而不是把整个任务当作一个任务进行调度）

### 第八章 调度：多级反馈队列
- MLFQ有多个优先级不同的队列，每个队列中的任务会由轮转方式执行。高优先级队列中的任务会被优先执行
- MLFQ不会为每个工作指定不变的优先级，而是会根据观察到的行为进行调整，总而言之，交互型作业（如不断放弃CPU来等待键盘输入的作业）会趋向于高优先级，CPU占用型作业会趋向于低优先级
- MLFQ的基本规则：
    1. 优先级高的任务会先于优先级低的任务执行
    2. 优先级相同的任务会以时间片轮转的方式运行
    3. 工作进入系统时，直接放在最高优先级队列中
    4. 工作用完在某一优先级中的时间配额时优先级降低一级
    5. 每隔一段时间，就把所有工作重新加入到最高优先级队列（避免饥饿）
- 一般而言，高优先级队列的运行时间片会短些，以保证交互性，低优先级队列的运行时间会长些，以保证效率
- 有的MLFQ实现会用固定的表数值进行配置，而有的会用数学公式调整优先级
- 有的MLFQ会将最高优先级队列设置为操作系统专属
- 有的MLFQ会允许用户给出建议的任务优先级

### 第十章 多处理器调度（高级）
- 多处理器与单CPU之间的基本区别：对硬件缓存（cache）的使用以及多处理器之间共享数据的方式
- 多处理器调度需要考虑的问题：缓存一致性、缓存亲和度
- 单队列的方式（SQMS）比较容易构建，负载均衡较好，但在扩展性和缓存亲和度方面有着固有的缺陷。多队列的方式（MQMS）有很好的扩展性和缓存亲和度，但实现负载均衡却很困难，也更复杂
- Linux社区的三种调度程序：O(1)调度程序、完全公平调度程序（CFS）、BF调度程序（BFS）
- O(1)与CFS采用多队列，BFS采用单队列
- O(1)是基于优先级的，使交互性得到了特别关注
- CFS是确定的比例调度方法（类似于步长调度）
- BFS也是基于比例调度，但方案更复杂，称为“最早最合适虚拟截止时间优先算法”（EEVEF）
- 步长调度：每个程序有自己的“票数”（与任务的工作量或优先级成正比），用一个大数除以票数得到步长，因此票数越多，步长越小。每当需要调度时，选择当前行程最小的任务进行调度，并让其行程增加步长值

### 第十三章 抽象：地址空间
- 经典的进程内存结构：程序代码段位于该进程地址空间顶部，下面紧接着是堆空间，堆空间向下扩展，地址空间的另一端是栈空间，栈空间向上扩展
- 一个进程的地址空间包含运行的程序的所有状态
- 虚拟内存的三个目标：
    1. 透明：程序对操作系统实现虚拟内存的方式无感知，似乎在使用自己的很大的私有内存
    2. 效率：时间和空间上的高效。在实现高效率时，操作系统需要借助硬件支持，如TLB这样的硬件功能
    3. 保护：确保进程受到保护，每个进程及操作系统的内存空间互相隔离
- C语言中打印出来的指针地址是虚拟内存地址

### 第十四章 插叙：内存操作API
- C程序中的栈内存由编译器自动申请和释放，堆内存则需要通过显式调用函数来申请和释放
- 用malloc为字符串分配空间时需要有额外1个字符的空间，用于存储字符串结束符
- 在某些情况下可以不用free()释放内存，比如当程序运行时间很短时，OS会在进程死亡时清理其分配的所有页面，但建议总是显式释放分配的内存
- mmap()可以在程序中创建一个匿名内存区域，其不与任何特定文件相关联，而是与交换空间相关联
- 用calloc()分配内存，会在返回前将其置零初始化
- realloc()可以创建一个更大的内存区域并把旧区域的内容复制到其中

### 第十五章 机制：地址转换
- 实现CPU虚拟化时遵循的一般准则为受限直接访问（LDE），其背后的想法为让程序运行的大部分指令直接访问硬件（为了保证高效），只在一些关键点（如进程发起系统调用或发生时钟中断）时由操作系统介入来确保“在正确时间正确地点做正确的事”。内存虚拟化的思想与之类似
- 高效和控制是现代操作系统的两个主要目标
- 用动态重定位实现虚拟内存的思想：用基址寄存器存储进程的起始物理内存地址，用界限寄存器存储进程能使用的最大物理内存地址（或范围）
- 对基址寄存器和界限寄存器的修改需要进入内核模式（出于安全考虑）
- 用户程序内存访问越界时CPU要能产生异常来阻止其执行
- 动态重定位方式的弊端在于地址空间被分为固定大小的槽块，使用率不一定高，会造成内部碎片

### 第十六章 分段
- 将进程地址空间完全加载到内存中的弊端：
    1. 栈和堆之间存在内存碎片
    2. 剩余物理内存无法提供连续区域放置完整的地址空间时进程会无法运行
- 分段（Segmentation）：在MMU中引入不止一个基址和界限寄存器对，给地址空间内每个逻辑段（segment）一对。在典型的地址空间里有三个逻辑不同的段：代码、栈和堆
- 硬件在地址转换时使用段寄存器，但它需要知道段内的偏移量，以及地址属于哪个段。通常的方法是用虚拟地址的开头几位来标识不同的段（显式），比如当使用14位虚拟地址量，用前2位来区分代码、栈、堆，后12位来表示偏移量。或是硬件通过地址产生方式来确定段（隐式），如果地址由程序计数器产生（由指令获取），则在代码段，如果基于栈或基址指针，则在栈段，其他在堆段
- 在后续的系统设计中，还实现了地址空间之间共享内存段，可带来效率的提升，但同时需要对地址转换过程做一些修改，且需要一些额外的硬件支持，即为每个段增加若干保护位，用于标识程序是否能够读写该段或执行其中的代码，并在地址转换过程中检查越界时额外新增对访问权限的检查
- 有的操作系统能分出大量较小的段，这会需要进一步的硬件支持，并在内存中保存某种段表，能带来更大的灵活性
- 分段会带来的问题：
    1. 进程上下文切换开销增加（额外寄存器）
    2. 需要管理物理内存的空闲空间（外部碎片），一般使用空闲列表管理算法

### 第十七章 空闲空间管理
- 大多数分配程序会在header中保存一些信息，通常在返回的内存块前（额外空间），这样free函数就只需要接收一个起始内存地址，而不需要传入内存空间的大小。**在释放空间时，头块也会被一同释放**
- header中还会保存一个魔法数字，用作正常性检查
- 空闲链表的节点可以是各个内存块的header（包括未被分配的内存），这样就可以减少用于维护信息的额外空间
- 伙伴系统：
    - 在这种系统中，空闲空间首先从概念上被看成大小为2N 的大空间。当有一个内存分配请求时，空闲空间被递归地一分为二，直到刚好可以满足请求的大小（再一分为二就无法满足）。这时，请求的块被返回给用户
    - 伙伴系统的漂亮之处在于块被释放时。如果将这个8KB的块归还给空闲列表，分配程序会检查“伙伴”8KB是否空闲。如果是，就合二为一，变成16KB 的块。然后会检查这个16KB块的伙伴是否空闲，如果是，就合并这两块。这个递归合并过程继续上溯，直到合并整个内存区域，或者某一个块的伙伴还没有被释放
    - 伙伴系统运转良好的原因，在于很容易确定某个块的伙伴（每对互为伙伴的块只有一位不同，正是这一位决定了它们在整个伙伴树中的层次）

### 第十八章 分页：介绍
- 分页不是将一个进程的地址空间分割成几个不同长度的逻辑段（即代码、堆、段），而是分割成固定大小的单元，每个单元称为一页。相应地，我们把物理内存看成是定长槽块的阵列，叫作页帧（pageframe）。每个这样的页帧包含一个虚拟内存
- 为了记录地址空间的每个虚拟页放在物理内存中的位置，操作系统通常为每个进程保存一个数据结构，称为页表（page table）。页表的主要作用是为地址空间的每个虚拟页面保存地址转换（address translation），从而让我们知道每个页在物理内存中的位置
- 分页机制可以消除外部碎片，支持稀疏虚拟地址空间，但会占用额外空间用于存储页表，并且会拖慢地址转换速度

### 第十九章 分页：快速地址转换（TLB）
- 使用分页作为核心机制来实现虚拟内存，可能会带来较高的性能开销。因为要使用分页，就要将内存地址空间切分成大量固定大小的单元（页），并且需要记录这些单元的地址映射信息
- TLB的本质是地址转换缓存，能带来巨大性能提升（靠近处理器附近的硬件单元，可以减少访问页表带来的内存访问）
- TLB未命中时会陷入内核执行TLB更新代码，**执行完毕后会返回导致陷阱的指令重试执行（以使缓存生效），而不是像其它的陷阱返回指令会返回到下一条指令继续执行**
- 运行TLB未命中代码时操作系统会保证其不会陷入无限循环的TLB未命中递归（比如预留一些操作系统代码需要使用的固定物理内存页信息）
- TLB的有效位与页表的有效位不是一回事，前者表示TLB位有否生效（用于保证上下文切换的安全性），后者表示页表有否被进程使用
- LRU不一定总是最好的，比如当一个程序循环访问n+1个页，而TLB只能放10个页，这意味着每次内存访问都无法命中缓存。这时用随机丢弃策略会更好

### 第二十章 分页：较小的表
- 如何去掉页表中的所有无效区域，而不是将它们全部保留在内存中？我们将这种方法称为多级页表（multi-level pagetable），因为它将线性页表变成了类似树的东西。这种方法非常有效，许多现代系统都用它
- 多级页表使用了名为页目录（page directory）的新结构。页目录因此可以告诉你页表的页在哪里，或者页表的整个页不包含有效页。这样不用所有页表都常驻于内存（页目录可以指向页表的各个部分）
- 多级页表分配的页表空间，与你正在使用的地址空间内存量成比例。因此它通常很紧凑，并且支持稀疏的地址空间
- 使用多级页表出现TLB未命中时会需要从内存加载两次（一次页目录，一次页表），比线性页表会多一次，因此多级页表是一个时间——空间的折中方案
- 页目录最好能完整放入一个页中，但事实的情况是为了提高内存利用率，页的大小会更小，而页数会因此变多，目录也因此变大，这时两级页表就不够了，需要引入更多级别的页表

### 第二十一章 超越物理内存：机制
- 这一章主要讲了用硬盘的交换空间实现虚拟内存的事情
- 发生页错误时会先由操作系统从硬盘中读取相应的内存页进入内存，等磁盘IO结束后再更新页表将此页标记为存在并重试指令，这时TLB会未命中，再接着走TLB未命中的流程
- 在上述步骤的IO阶段进程是阻塞状态，操作系统可以自由地运行其它可执行的进程
- 大多数操作系统会设置高低水位线来帮助决定何时从内存中清除页（每次满了才清楚页的话效率太低了）

### 第二十二章 超越物理内存：策略
- 内存页的LRU算法比看上去要难实现，因为需要使用额外的位来存储时间信息，以及需要遍历大量的页来精确找到LRU页。因此近似LRU算法会更常用一些（通过时钟指针标明某个页最近是否被使用过）
- 将页从内存踢出时，如果页是脏页则需要重写回磁盘，如果没被修改可以直接舍弃，这可以通过一个硬件修改位来实现
- 可以利用代码的局部性特征来预载入一些内存页以提高性能
- 抖动：内存被超额请求导致操作系统不断进行换页。某些版本的Linux会直接干死这种进程

### 第二十三章 VAX/VMS虚拟内存系统
- 这一章以后再看